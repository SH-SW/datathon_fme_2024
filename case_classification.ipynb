{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and Data Loading\n",
    "\n",
    "In this section, we load the MNIST dataset and perform normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalizing data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Expanding dimensions to add a grayscale channel\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "input_shape = x_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "\n",
    "We build a convolutional neural network model to classify MNIST images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EnricPereraiBel\\T2C\\AI_CHAPTER\\git\\mlflow_uni_demo\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Building the deep learning model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "learning_rate = 0.1\n",
    "# Setting up the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "We define the training parameters and train the model, using MLflow to log metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.1014 - loss: 4.8090 - val_accuracy: 0.0958 - val_loss: 2.3054\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.1065 - loss: 2.3101 - val_accuracy: 0.0980 - val_loss: 2.3072\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.1055 - loss: 2.3095 - val_accuracy: 0.1135 - val_loss: 2.3114\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.1013 - loss: 2.3096 - val_accuracy: 0.1135 - val_loss: 2.3115\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.1070 - loss: 2.3104 - val_accuracy: 0.1028 - val_loss: 2.3066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 18:46:47 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/11/15 18:46:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x2178390cad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "# Starting an MLflow experiment\n",
    "mlflow.start_run()\n",
    "\n",
    "# Logging parameters to MLflow\n",
    "mlflow.log_param(\"epochs\", epochs)\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "mlflow.log_param(\"optimizer\", \"adam\")\n",
    "mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "\n",
    "class MLflowEpochCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            mlflow.log_metric(\"train_accuracy\", logs.get(\"accuracy\"))\n",
    "            mlflow.log_metric(\"train_loss\", logs.get(\"loss\"))\n",
    "            mlflow.log_metric(\"val_accuracy\", logs.get(\"val_accuracy\"))\n",
    "            mlflow.log_metric(\"val_loss\", logs.get(\"val_loss\"))\n",
    "            mlflow.log_metric(\"epoch\", epoch)\n",
    "mlflow_callback = MLflowEpochCallback()\n",
    "            \n",
    "# Trainning the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[mlflow_callback])\n",
    "\n",
    "# Saving the model to MLflow\n",
    "mlflow.keras.log_model(model, artifact_path=\"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "We evaluate the model on the test set and log the final metrics to MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1027 - loss: 2.3051\n",
      "Test loss: 2.3065989017486572, Test accuracy: 0.10279999673366547\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n",
    "\n",
    "# Logging final metrics to MLflow\n",
    "mlflow.log_metric(\"test_loss\", test_loss)\n",
    "mlflow.log_metric(\"test_accuracy\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Explanation with SHAP\n",
    "\n",
    "We generate explanations for the model's predictions using SHAP and save them in MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EnricPereraiBel\\T2C\\AI_CHAPTER\\git\\mlflow_uni_demo\\.venv\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: keras_tensor. Received: the structure of inputs=['*']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
     ]
    }
   ],
   "source": [
    "# Creating a directory for SHAP images if it doesn't exist\n",
    "shap_images_dir = \"shap_images\"\n",
    "os.makedirs(shap_images_dir, exist_ok=True)\n",
    "\n",
    "# Using SHAP to explain the model\n",
    "background = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "test_images = x_test[:10]\n",
    "\n",
    "# Creating the SHAP explainer and get SHAP values\n",
    "explainer = shap.GradientExplainer(model, background)\n",
    "shap_values = explainer.shap_values(test_images)\n",
    "\n",
    "# Getting the model predictions\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Saving SHAP explanations in MLflow\n",
    "for i in range(len(test_images)):\n",
    "    shap_image = os.path.join(shap_images_dir, f\"shap_explanation_{i}.png\")\n",
    "    shap_value = shap_values[i][:, :, :, predicted_classes[i]]\n",
    "    \n",
    "    # Visualizing and save the SHAP explanation\n",
    "    shap.image_plot([shap_value], -test_images[i], show=False)\n",
    "    plt.savefig(shap_image, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Logging the image to MLflow\n",
    "    mlflow.log_artifact(shap_image, artifact_path=\"shap_images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End the MLflow Experiment\n",
    "\n",
    "We end the experiment run in MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ending the MLflow run\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
