{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(df.iloc[0,:])\n",
    "display(df['UnitTypes.UnitTypeType'][700:1400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characteristics.LotFeatures\n",
    "nombre_columna = 'Characteristics.LotFeatures'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "elementos = list(itertools.chain.from_iterable(elementos))\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        elemento = ast.literal_eval(elemento)\n",
    "        v = [0] * set_size\n",
    "        for feature in elemento:\n",
    "            index = unique_result.index(feature)\n",
    "            v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "Characteristics_LotFeatures_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characteristics.LotSizeSquareFeet\n",
    "nombre_columna = 'Characteristics.LotSizeSquareFeet'\n",
    "lista = []\n",
    "\n",
    "media = df[nombre_columna].mean()\n",
    "lista = df[nombre_columna].tolist()-media\n",
    "lista = np.nan_to_num(lista, nan=0)\n",
    "\n",
    "Characteristics_LotSizeSquareFeet = lista/max(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageData.c1c6\n",
    "a1 = df['ImageData.c1c6.summary.bathroom'].tolist()-df['ImageData.c1c6.summary.bathroom'].mean()\n",
    "a2 = df['ImageData.c1c6.summary.exterior'].tolist()-df['ImageData.c1c6.summary.exterior'].mean()\n",
    "a3 = df['ImageData.c1c6.summary.interior'].tolist()-df['ImageData.c1c6.summary.interior'].mean()\n",
    "a4 = df['ImageData.c1c6.summary.kitchen'].tolist()-df['ImageData.c1c6.summary.kitchen'].mean()\n",
    "a5 = df['ImageData.c1c6.summary.property'].tolist()-df['ImageData.c1c6.summary.property'].mean()\n",
    "\n",
    "a1 = np.nan_to_num(a1, nan=0)\n",
    "a2 = np.nan_to_num(a2, nan=0)\n",
    "a3 = np.nan_to_num(a3, nan=0)\n",
    "a4 = np.nan_to_num(a4, nan=0)\n",
    "a5 = np.nan_to_num(a5, nan=0)\n",
    "\n",
    "ImageData_c1c6_summary_bathroom = a1/max(a1)\n",
    "ImageData_c1c6_summary_exterior = a2/max(a2)\n",
    "ImageData_c1c6_summary_interior = a3/max(a3)\n",
    "ImageData_c1c6_summary_kitchen = a4/max(a4)\n",
    "ImageData_c1c6_summary_property = a5/max(a5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageData.q1q6\n",
    "a1 = df['ImageData.q1q6.summary.bathroom'].tolist()-df['ImageData.q1q6.summary.bathroom'].mean()\n",
    "a2 = df['ImageData.q1q6.summary.exterior'].tolist()-df['ImageData.q1q6.summary.exterior'].mean()\n",
    "a3 = df['ImageData.q1q6.summary.interior'].tolist()-df['ImageData.q1q6.summary.interior'].mean()\n",
    "a4 = df['ImageData.q1q6.summary.kitchen'].tolist()-df['ImageData.q1q6.summary.kitchen'].mean()\n",
    "a5 = df['ImageData.q1q6.summary.property'].tolist()-df['ImageData.q1q6.summary.property'].mean()\n",
    "\n",
    "a1 = np.nan_to_num(a1, nan=0)\n",
    "a2 = np.nan_to_num(a2, nan=0)\n",
    "a3 = np.nan_to_num(a3, nan=0)\n",
    "a4 = np.nan_to_num(a4, nan=0)\n",
    "a5 = np.nan_to_num(a5, nan=0)\n",
    "\n",
    "ImageData_q1q6_summary_bathroom = a1/max(a1)\n",
    "ImageData_q1q6_summary_exterior = a2/max(a2)\n",
    "ImageData_q1q6_summary_interior = a3/max(a3)\n",
    "ImageData_q1q6_summary_kitchen = a4/max(a4)\n",
    "ImageData_q1q6_summary_property = a5/max(a5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageData.features_reso.results\n",
    "nombre_columna = 'ImageData.features_reso.results'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "elementos = list(itertools.chain.from_iterable(elementos))\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        elemento = ast.literal_eval(elemento)\n",
    "        v = [0] * set_size\n",
    "        for feature in elemento:\n",
    "            index = unique_result.index(feature)\n",
    "            v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "ImageData_features_reso_results_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageData.room_type_reso.results\n",
    "nombre_columna = 'ImageData.room_type_reso.results'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "elementos = list(itertools.chain.from_iterable(elementos))\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        elemento = ast.literal_eval(elemento)\n",
    "        v = [0] * set_size\n",
    "        for feature in elemento:\n",
    "            index = unique_result.index(feature)\n",
    "            v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "ImageData_room_type_reso_results_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageData.style.exterior.summary.label\n",
    "nombre_columna = 'ImageData.style.exterior.summary.label'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].tolist()\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        v = [0] * set_size\n",
    "        index = unique_result.index(elemento)\n",
    "        v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "ImageData_style_exterior_summary_label_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location.Address.PostalCode\n",
    "nombre_columna = 'Location.Address.PostalCode'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].tolist()\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        v = [0] * set_size\n",
    "        index = unique_result.index(elemento)\n",
    "        v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "Location_Address_PostalCode_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location.Address.CountyOrParish\n",
    "nombre_columna = 'Location.Address.CountyOrParish'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].tolist()\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        v = [0] * set_size\n",
    "        index = unique_result.index(elemento)\n",
    "        v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "Location_Address_CountyOrParish_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property.PropertyType\n",
    "nombre_columna = 'Property.PropertyType'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].tolist()\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        v = [0] * set_size\n",
    "        index = unique_result.index(elemento)\n",
    "        v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "Property_PropertyType_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure.Basement\n",
    "nombre_columna = 'Structure.Basement'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "elementos = list(itertools.chain.from_iterable(elementos))\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        elemento = ast.literal_eval(elemento)\n",
    "        v = [0] * set_size\n",
    "        for feature in elemento:\n",
    "            index = unique_result.index(feature)\n",
    "            v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "Structure_Basement_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure.BathroomsFull, Structure.BathroomsHalf, Structure.BedroomsTotal\n",
    "a1 = df['Structure.BathroomsFull'].tolist()-df['Structure.BathroomsFull'].mean()\n",
    "a2 = df['Structure.BathroomsHalf'].tolist()-df['Structure.BathroomsHalf'].mean()\n",
    "a3 = df['Structure.BedroomsTotal'].tolist()-df['Structure.BedroomsTotal'].mean()\n",
    "\n",
    "a1 = np.nan_to_num(a1, nan=0)\n",
    "a2 = np.nan_to_num(a2, nan=0)\n",
    "a3 = np.nan_to_num(a3, nan=0)\n",
    "\n",
    "Structure_BedroomsFull = a1/max(a1)\n",
    "Structure_BedroomsHalf = a2/max(a2)\n",
    "Structure_BedroomsTotal = a3/max(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure.BelowGradeFinishedArea, Structure.BelowGradeUnfinishedArea\n",
    "a1 = df['Structure.BelowGradeFinishedArea'].tolist()-df['Structure.BelowGradeFinishedArea'].mean()\n",
    "a2 = df['Structure.BelowGradeUnfinishedArea'].tolist()-df['Structure.BelowGradeUnfinishedArea'].mean()\n",
    "\n",
    "a1 = np.nan_to_num(a1, nan=0)\n",
    "a2 = np.nan_to_num(a2, nan=0)\n",
    "\n",
    "Structure_BelowGradeFinishedArea = a1/max(a1)\n",
    "Structure_BelowGradeUnfinishedArea = a2/max(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure.Cooling\n",
    "nombre_columna = 'Structure.Cooling'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "elementos = list(itertools.chain.from_iterable(elementos))\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        elemento = ast.literal_eval(elemento)\n",
    "        v = [0] * set_size\n",
    "        for feature in elemento:\n",
    "            index = unique_result.index(feature)\n",
    "            v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "Structure_Cooling_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure.Heating\n",
    "nombre_columna = 'Structure.Heating'\n",
    "lista = []\n",
    "\n",
    "elementos = df[nombre_columna].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "elementos = list(itertools.chain.from_iterable(elementos))\n",
    "unique_result = list(set(elementos))\n",
    "set_size = len(unique_result)\n",
    "\n",
    "\n",
    "elementos = df[nombre_columna]\n",
    "i = 0\n",
    "for elemento in elementos:\n",
    "    if pd.notna(elemento):\n",
    "        elemento = ast.literal_eval(elemento)\n",
    "        v = [0] * set_size\n",
    "        for feature in elemento:\n",
    "            index = unique_result.index(feature)\n",
    "            v[index] = 1\n",
    "        lista.append(v)\n",
    "    else:\n",
    "        lista.append([0] * set_size)\n",
    "    i = i+1\n",
    "\n",
    "Structure_Heating_c = lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure.FireplacesTotal, Structure.GarageSpaces, Structure.LivingArea, Structure.NewConstructionYN, Structure.Rooms.RoomsTotal\n",
    "a1 = df['Structure.LivingArea'].tolist()-df['Structure.LivingArea'].mean()\n",
    "a2 = df['Structure.GarageSpaces'].tolist()-df['Structure.GarageSpaces'].mean()\n",
    "a3 = df['Structure.GarageSpaces'].tolist()-df['Structure.GarageSpaces'].mean()\n",
    "a4 = df['Structure.NewConstructionYN'].tolist()-df['Structure.NewConstructionYN'].mean()\n",
    "a5 = df['Structure.Rooms.RoomsTotal'].tolist()-df['Structure.Rooms.RoomsTotal'].mean()\n",
    "\n",
    "a1 = np.nan_to_num(a1, nan=0)\n",
    "a2 = np.nan_to_num(a2, nan=0)\n",
    "a3 = np.nan_to_num(a3, nan=0)\n",
    "a4 = np.nan_to_num(a4, nan=0)\n",
    "a5 = np.nan_to_num(a5, nan=0)\n",
    "\n",
    "Structure_FireplacesTotal = a1/max(a1)\n",
    "Structure_GarageSpaces = a2/max(a2)\n",
    "Structure_LivingArea = a3/max(a3)\n",
    "Structure_NewConstructionYN = a4/max(a4)\n",
    "Structure_Rooms_RoomsTotal = a5/max(a5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios = df['Listing.Price.ClosePrice'].tolist()/df['Listing.Price.ClosePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2. Convert to PyTorch tensors and move them to the GPU (if available)\n",
    "\n",
    "tensor1 = torch.tensor(Characteristics_LotFeatures_c, dtype=torch.bool).to(device)\n",
    "tensor2 = torch.tensor(Characteristics_LotSizeSquareFeet, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor3 = torch.tensor(ImageData_c1c6_summary_bathroom, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor4 = torch.tensor(ImageData_c1c6_summary_exterior, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor5 = torch.tensor(ImageData_c1c6_summary_interior, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor6 = torch.tensor(ImageData_c1c6_summary_kitchen, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor7 = torch.tensor(ImageData_c1c6_summary_property, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor8 = torch.tensor(ImageData_q1q6_summary_bathroom, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor9 = torch.tensor(ImageData_q1q6_summary_exterior, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor10 = torch.tensor(ImageData_q1q6_summary_interior, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor11 = torch.tensor(ImageData_q1q6_summary_kitchen, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor12 = torch.tensor(ImageData_q1q6_summary_property, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor13 = torch.tensor(ImageData_features_reso_results_c, dtype=torch.bool).to(device)\n",
    "tensor14 = torch.tensor(ImageData_room_type_reso_results_c, dtype=torch.bool).to(device)\n",
    "tensor15 = torch.tensor(ImageData_style_exterior_summary_label_c, dtype=torch.bool).to(device)\n",
    "tensor16 = torch.tensor(Location_Address_PostalCode_c, dtype=torch.bool).to(device)\n",
    "tensor17 = torch.tensor(Location_Address_CountyOrParish_c, dtype=torch.bool).to(device)\n",
    "tensor18 = torch.tensor(Property_PropertyType_c, dtype=torch.bool).to(device)\n",
    "tensor19 = torch.tensor(Structure_Basement_c, dtype=torch.bool).to(device)\n",
    "tensor20 = torch.tensor(Structure_BedroomsFull, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor21 = torch.tensor(Structure_BedroomsHalf, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor22 = torch.tensor(Structure_BedroomsTotal, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor23 = torch.tensor(Structure_BelowGradeFinishedArea, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor24 = torch.tensor(Structure_BelowGradeUnfinishedArea, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor25 = torch.tensor(Structure_Cooling_c, dtype=torch.bool).to(device)\n",
    "tensor26 = torch.tensor(Structure_Heating_c, dtype=torch.bool).to(device)\n",
    "tensor27 = torch.tensor(Structure_FireplacesTotal, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor28 = torch.tensor(Structure_GarageSpaces, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor29 = torch.tensor(Structure_LivingArea, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor30 = torch.tensor(Structure_NewConstructionYN, dtype=torch.float32).view(-1, 1).to(device)\n",
    "tensor31 = torch.tensor(Structure_Rooms_RoomsTotal, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "input_dim = sum(\n",
    "    tensor.shape[1] for tensor in [\n",
    "        tensor1, tensor2, tensor3, tensor4, tensor5, tensor6, tensor7, tensor8, tensor9, tensor10,\n",
    "        tensor11, tensor12, tensor13, tensor14, tensor15, tensor16, tensor17, tensor18, tensor19, tensor20,\n",
    "        tensor21, tensor22, tensor23, tensor24, tensor25, tensor26, tensor27, tensor28, tensor29, tensor30, tensor31\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_tensor = torch.cat((\n",
    "    tensor1, tensor2, tensor3, tensor4, tensor5, tensor6, tensor7, tensor8, tensor9, tensor10,\n",
    "    tensor11, tensor12, tensor13, tensor14, tensor15, tensor16, tensor17, tensor18, tensor19, tensor20,\n",
    "    tensor21, tensor22, tensor23, tensor24, tensor25, tensor26, tensor27, tensor28, tensor29, tensor30, tensor31\n",
    "), dim=1).to(device)\n",
    "\n",
    "\n",
    "y_tensor = torch.tensor(precios, dtype=torch.float32).view(-1, 1).to(device)\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Batching\n",
    "batch_size = 150\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 3. Define a simple polynomial regression model (using a neural network)\n",
    "class ModeloML(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModeloML, self).__init__()\n",
    "\n",
    "        # Single hidden layer (with one input feature for x and one output for y)\n",
    "        self.fc1 = nn.Linear(input_dim, 1000)   # First hidden layer (input to hidden)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 100)   # Output layer (from hidden to output)\n",
    "        self.fc4 = nn.Linear(100, 10)   # Output layer (from hidden to output)\n",
    "        self.fc5 = nn.Linear(10, 1)\n",
    "        self.relu = nn.ReLU()         # ReLU activation for non-linearity\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))  # First hidden layer\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)             # Output layer\n",
    "        return x\n",
    "\n",
    "# 4. Instantiate the model and move it to the GPU (if available)\n",
    "model = ModeloML().to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_weights)\n",
    "# 5. Define the loss function (Mean Squared Error) and optimizer (Stochastic Gradient Descent)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1)\n",
    "\n",
    "# 6. Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        # Move data to device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 7. Plot results\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_tensor).cpu().numpy()  # Move predictions to CPU for plotting\n",
    "\n",
    "# Plot the original data and the regression curve\n",
    "plt.scatter(list(range(len(precios))), precios, label=\"Original Data\", color='blue',linewidth=0.01)\n",
    "plt.scatter(list(range(len(precios))), y_pred, label=\"Fitted Polynomial Regression\", color='red', linewidth=0.01)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_tensor).cpu().numpy()  # Move predictions to CPU for plotting\n",
    "\n",
    "# Plot the original data and the regression curve\n",
    "plt.scatter(list(range(len(precios))), precios, label=\"Original Data\", color='blue',linewidth=0.01)\n",
    "plt.scatter(list(range(len(precios))), y_pred, label=\"Fitted Polynomial Regression\", color='red', linewidth=0.01)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1000)\n",
    "epoch = 0\n",
    "while True:\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    # Forward pass: Compute predicted y\n",
    "    y_pred = model(X_tensor)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "    \n",
    "    # Backward pass: Compute gradients\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    loss.backward()  # Backpropagation\n",
    "    \n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    print(f\"Epoch [{epoch}], Loss: {loss.item():.4f}\")\n",
    "    epoch = epoch+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
